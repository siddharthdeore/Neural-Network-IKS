{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1600x1200 with 12 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 32\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 3s 25ms/step - loss: 1.7369\n"
     ]
    }
   ],
   "source": [
    "import keras \n",
    "import numpy as np\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Activation, LeakyReLU, Input, Lambda, Concatenate\n",
    "from keras.losses import mean_absolute_error, mean_squared_error\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from keras import optimizers\n",
    "from keras import metrics\n",
    "import scipy.io\n",
    "import tensorflow as tf\n",
    "import keras.backend as K\n",
    "from IPython.display import clear_output\n",
    "import math\n",
    "\n",
    "def transform_matrix(theta, d, a, alpha):\n",
    "    return np.array([[np.cos(theta), -np.sin(theta)*np.cos(alpha), np.sin(theta)*np.sin(alpha), a*np.cos(theta)], \n",
    "                     [np.sin(theta), np.cos(theta)*np.cos(alpha), -np.cos(theta)*np.sin(alpha), a*np.sin(theta)], \n",
    "                     [0, np.sin(alpha), np.cos(alpha), d], \n",
    "                     [0, 0, 0, 1]])\n",
    "  \n",
    "def forward_kinematics_2(theta1, theta2):\n",
    "    T00 = transform_matrix(theta1,0,1,0)\n",
    "    T01 = transform_matrix(theta2,0,1,0)\n",
    "    pos = [0, 0, 0, 1]\n",
    "    Etip = np.matmul(np.matmul(T00, T01), pos)\n",
    "    return T00, T01, Etip\n",
    "\n",
    "def get_positions_2(theta):\n",
    "    # assuming theta is already in radian\n",
    "    theta1 = theta[0]\n",
    "    theta2 = theta[1]\n",
    "    \n",
    "    T00, T01, Etip = forward_kinematics_2(theta1, theta2)\n",
    "    t = np.transpose(np.array([[0, 0, 0, 1]]))\n",
    "    pos_1 = np.matmul(T00, t)\n",
    "    \n",
    "    # only return first 2 elements as xy\n",
    "    return np.array([pos_1[:2], np.reshape(Etip[:2], (2, 1))])\n",
    "  \n",
    "def transform_matrix_tensor(theta, d, a, alpha):\n",
    "    # tensor version of transform matrix\n",
    "    matrix = [[tf.cos(theta), tf.multiply(-tf.sin(theta), tf.cos(alpha)), tf.multiply(tf.sin(theta), tf.sin(alpha)), tf.multiply(a, tf.cos(theta))], \n",
    "              [tf.sin(theta), tf.multiply(tf.cos(theta), tf.cos(alpha)), tf.multiply(-tf.cos(theta), tf.sin(alpha)), tf.multiply(a, tf.sin(theta))], \n",
    "              [tf.zeros_like(theta), tf.sin(alpha), tf.cos(alpha), d], \n",
    "              [tf.zeros_like(theta), tf.zeros_like(theta), tf.zeros_like(theta), tf.ones_like(theta)]]\n",
    "    return matrix\n",
    "  \n",
    "def batch_matmul(location_v, batch_theta_v):\n",
    "    # perform matrix multiplication between the location vector and the transform matrix, \n",
    "    # independently for each example in the batch, but done in a parallel way\n",
    "    zeros = tf.zeros_like(batch_theta_v)\n",
    "    ones = tf.ones_like(batch_theta_v)\n",
    "    m0 = transform_matrix_tensor(batch_theta_v, zeros, ones, zeros)\n",
    "    m = tf.multiply(m0, location_v)\n",
    "    m = tf.reduce_sum(m, axis=1)\n",
    "    m = tf.transpose(m)\n",
    "    return m\n",
    "  \n",
    "def forward_kinematics_loss_2(y_true, y_pred):\n",
    "    # y_true is the xy position\n",
    "    # y_pred is the 2-dimensional theta output\n",
    "    theta1 = y_pred[:, 0]\n",
    "    theta2 = y_pred[:, 1]\n",
    "    zeros = tf.zeros_like(theta1)\n",
    "    zeros = K.expand_dims(zeros, axis=1)\n",
    "    \n",
    "    location_v = K.concatenate([zeros, zeros, zeros, zeros+1], axis=1)\n",
    "    location_v = K.expand_dims(location_v, axis=-1)\n",
    "    location_v = K.concatenate([location_v]*4, axis=2)\n",
    "    location_v = tf.transpose(location_v, perm=[2, 1, 0])\n",
    "    \n",
    "    end_tip_1st_segment = batch_matmul(location_v, theta1)\n",
    "    \n",
    "    location_v = K.expand_dims(end_tip_1st_segment, axis=-1)\n",
    "    location_v = K.concatenate([location_v]*4, axis=2)\n",
    "    location_v = tf.transpose(location_v, perm=[2, 1, 0])\n",
    "    \n",
    "    end_tip_2nd_segment = batch_matmul(location_v, theta2)\n",
    "    \n",
    "    xy = end_tip_2nd_segment[:, :2]\n",
    "    loss1 = K.mean(K.square(xy - y_true))\n",
    "    pi = tf.constant(math.pi)\n",
    "    loss2 = K.mean(tf.maximum(tf.abs(y_pred)-[[pi, 0.5 * pi]], 0))\n",
    "    loss = loss1 + loss2\n",
    "    return loss\n",
    "  \n",
    "def get_xy_and_theta_2(num):\n",
    "    xy = np.zeros((num, 2))\n",
    "    theta = np.zeros((num, 3))\n",
    "\n",
    "    theta[:,0] = (np.random.random((num)) * 2 * np.pi) - np.pi\n",
    "    theta[:,1] = (np.random.random((num)) * np.pi) - (0.5 * np.pi)\n",
    "    for i in range(num):\n",
    "        _, _, temp = forward_kinematics_2(theta[i,0], theta[i,1])\n",
    "        xy[i, :] = temp[:2]\n",
    "    return xy, theta\n",
    "\n",
    "K.clear_session()\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(256, input_shape=(2,)),\n",
    "    LeakyReLU(),\n",
    "    Dense(256),\n",
    "    LeakyReLU(),\n",
    "    Dense(256),\n",
    "    LeakyReLU(),\n",
    "    Dense(256),\n",
    "    LeakyReLU(),\n",
    "    Dense(256),\n",
    "    LeakyReLU(),\n",
    "    Dense(256),\n",
    "    LeakyReLU(),\n",
    "    Dense(256),\n",
    "    LeakyReLU(),\n",
    "    Dense(2)       # <==== Change this to the number of angles predicted\n",
    "])\n",
    "\n",
    "adam = optimizers.Adam(lr=1e-6)\n",
    "model.compile(optimizer=adam,\n",
    "              loss=forward_kinematics_loss_2)\n",
    "\n",
    "loss_hist = []\n",
    "error_hist = []\n",
    "\n",
    "EPOCHS = 100000\n",
    "xy_test, theta_test = get_xy_and_theta_2(10000)\n",
    "\n",
    "for i in range(EPOCHS):\n",
    "    # train on a mini-batch\n",
    "    print(\"epoch {}\".format(i))\n",
    "    xy_train, theta_train = get_xy_and_theta_2(100)\n",
    "    history = model.fit(xy_train, xy_train, epochs=1, batch_size=1, verbose = 1)\n",
    "    \n",
    "    # test the model on the test set\n",
    "    theta_pred = model.predict(xy_test)\n",
    "    xy_pred = np.zeros((theta_pred.shape[0], 2))\n",
    "    for j in range(theta_pred.shape[0]):\n",
    "        a = get_positions_2(np.squeeze(theta_pred[j, :]))\n",
    "        xy_pred[j, :] = a[1, :, 0]\n",
    "    error = np.mean(np.square(xy_pred - xy_test))\n",
    "    \n",
    "    # plot (1) loss & (2) mean square error on test set, vs. training steps\n",
    "    loss_hist.append(history.history['loss'][0])\n",
    "    error_hist.append(error)\n",
    "    clear_output()\n",
    "    plt.figure(figsize=(16, 4))\n",
    "    line1, = plt.plot(error_hist, label=\"error hist\")\n",
    "    line2, = plt.plot(loss_hist, label=\"loss hist\")\n",
    "    plt.grid()\n",
    "    plt.title('mean squraed error on test set vs. epoch')\n",
    "    plt.legend((line1, line2), ('error hist', 'loss hist'))\n",
    "    plt.show()\n",
    "\n",
    "    # randomly showcase 12 examples to visually see how the network is doing\n",
    "    xy_temp, theta_temp = get_xy_and_theta_2(12)\n",
    "    fig, ax = plt.subplots(nrows=3, ncols=4, figsize=(16, 12))\n",
    "    for i, row in enumerate(ax):\n",
    "        for j, col in enumerate(row):\n",
    "            idx = j + i * 4\n",
    "            theta = model.predict(np.reshape(xy_temp[idx], (1, 2)))\n",
    "            \n",
    "            # plot xy from predicted angles and ground truth, for 2-segment arm\n",
    "            a = get_positions_2(np.squeeze(theta))\n",
    "            col.plot([0, a[0][0]], [0, a[0][1]])\n",
    "            col.plot([a[0][0], a[1][0]], [a[0][1], a[1][1]])\n",
    "            col.plot(xy_temp[idx][0], xy_temp[idx][1], 'bo', markersize=10)\n",
    "            col.plot(a[1][0], a[1][1], 'ro', markersize=10)\n",
    "            col.set_xlim([-3, 3])\n",
    "            col.set_ylim([-3, 3])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
